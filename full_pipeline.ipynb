{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62078559",
   "metadata": {},
   "source": [
    "**Loading necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14e349cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from backend.db import messages_collection, threads_collection\n",
    "from typing import Literal\n",
    "from datetime import datetime, timezone\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81e63704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"‚úÖ API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4d90d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8a52f",
   "metadata": {},
   "source": [
    "**Loading and Processing Document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1c543a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ‚úÖ Loaded 4 pages from Amendment_of_the_National_Law_on_NELFUND.pdf\n",
      "2 ‚úÖ Loaded 11 pages from Explanatory_Memorandum_For_Students-Loans_Act_2023.pdf\n",
      "3 ‚úÖ Loaded 4 pages from FAQs_On_NELFUND_Student_Loan.pdf\n",
      "4 ‚úÖ Loaded 14 pages from Guidelines_For_Nelfund_Loan.pdf\n",
      "5 ‚úÖ Loaded 4 pages from Terms&Conditions_of_Students_Loan.pdf\n",
      "\n",
      "Total pages loaded: 37\n"
     ]
    }
   ],
   "source": [
    "document_path = r\"agent\\data\"\n",
    "document_list = os.listdir(document_path)\n",
    "all_pages = []\n",
    "\n",
    "for i, file in enumerate(document_list, start=1):\n",
    "    file_path = os.path.join(document_path, file)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è File not found: {file_path}\")\n",
    "    else:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pages = loader.load()  # simpler sync loading for notebook\n",
    "        all_pages.extend(pages)\n",
    "        print(f\"{i} ‚úÖ Loaded {len(pages)} pages from {file}\")\n",
    "\n",
    "print(f\"\\nTotal pages loaded: {len(all_pages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42656501",
   "metadata": {},
   "source": [
    "**Split into Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7927b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 55 chunks\n",
      "Sample chunk:\n",
      "Amendment  of  the  National  Law  on  NELFUND  \n",
      " \n",
      " \n",
      "President\n",
      " \n",
      "Bola\n",
      " \n",
      "Tinubu,\n",
      " \n",
      "on\n",
      " \n",
      "Wednesday,\n",
      " \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(all_pages)\n",
    "print(f\"‚úÖ Created {len(doc_splits)} chunks\")\n",
    "print(f\"Sample chunk:\\n{doc_splits[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e722e",
   "metadata": {},
   "source": [
    "**Create Vector Store (Chroma)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6937616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings model initialized\n",
      "‚úÖ Vector store created with 55 chunks\n",
      "   Persisted to: agent\\database\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "print(\"‚úÖ Embeddings model initialized\")\n",
    "\n",
    "chroma_path = r\"agent\\database\\chroma_db\"\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"agentic_rag_docs\",\n",
    "    persist_directory=chroma_path,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "vectorstore.add_documents(documents=doc_splits)\n",
    "print(f\"‚úÖ Vector store created with {len(doc_splits)} chunks\")\n",
    "print(f\"   Persisted to: {chroma_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381fcdd",
   "metadata": {},
   "source": [
    "**Test Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5be670f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Nelfund?\n",
      "\n",
      "Top result:\n",
      "2  \n",
      "education sector through NELFUND, Nigeria is unlocking immense potentials \n",
      "by paving ways for br...\n",
      "\n",
      "‚úÖ Retrieval working!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the vector store\n",
    "test_query = \"What is Nelfund?\"\n",
    "test_results = vectorstore.similarity_search(test_query, k=2)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"\\nTop result:\")\n",
    "print(f\"{test_results[0].page_content[:100]}...\")\n",
    "print(f\"\\n‚úÖ Retrieval working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5784df",
   "metadata": {},
   "source": [
    "**Create Retrieval Tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ebaca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_nelfund_docs(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for relevant documents in the knowledge base.\n",
    "    Search for official NELFUND policy documents, eligibility, and application guides.\n",
    "    Use ONLY for factual questions about student loans.\n",
    "    \n",
    "    Use this tool when you need information from the document collection\n",
    "    to answer the user's question. Do NOT use this for:\n",
    "    - Greetings or small talk\n",
    "    \n",
    "    Args:\n",
    "        query: The search query describing what information is needed\n",
    "        \n",
    "    Returns:\n",
    "        Relevant document excerpts that can help answer the question\n",
    "    \"\"\"\n",
    "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant NELFUND documents found.\"\n",
    "    \n",
    "    formatted = \"\\n\\n\".join(\n",
    "        f\"Content: {doc.page_content}\\nSource: {doc.metadata.get('source', 'unknown')}\"\n",
    "        for doc in results\n",
    "    )\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b21bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool result (first 300 chars):\n",
      "Content: 10  \n",
      "LOAN REPAYMENT \n",
      "charges payment, such as falsifying student information/records or \n",
      "colluding with students to obtain loans for ineligible purposes. \n",
      "‚ñ™ The institution fails to refund disbursed institutional charges in instances \n",
      "stipulated in Section 5.5 above. \n",
      "‚ñ™ The institution fail...\n"
     ]
    }
   ],
   "source": [
    "# Test tool directly\n",
    "test_result = retrieve_nelfund_docs.invoke({\"query\": \"When does repayment starts?\"})\n",
    "print(f\"Tool result (first 300 chars):\\n{test_result[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3bd2e3",
   "metadata": {},
   "source": [
    "### **Building Agentic RAG System**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc518e49",
   "metadata": {},
   "source": [
    "**System Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d90400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ System prompt configured\n"
     ]
    }
   ],
   "source": [
    "system_prompt = SystemMessage(content=\"\"\"You are the NELFUND Navigator, a specialized conversational assistant designed exclusively to answer questions about the Nigerian Education Loan Fund (NELFUND) using only documents provided through retrieval.\n",
    "\n",
    "Your role is limited to producing accurate, factual, and helpful responses that are strictly grounded in retrieved NELFUND documents.\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "SCOPE AND AUTHORITY\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "You are strictly limited to NELFUND-related information.\n",
    "\n",
    "You must not use general knowledge, assumptions, prior training, or external sources.\n",
    "\n",
    "You must not answer questions about any topic outside NELFUND.\n",
    "\n",
    "If a question is not about NELFUND, or if the answer is not explicitly contained in the retrieved documents and it's not greeting and exchanging of names, you must respond with exactly the following text and nothing else:\n",
    "\n",
    "Can't provide\n",
    "\n",
    "Do not explain why. Do not add extra text.\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CONDITIONAL RETRIEVAL DECISION AUTHORITY\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "You are allowed to determine that retrieval is unnecessary for certain inputs.\n",
    "\n",
    "Retrieval must NOT be used for the following categories of input:\n",
    "Greetings such as hi, hello, good morning, good afternoon, or good evening.\n",
    "Polite expressions such as thank you or thanks.\n",
    "Identity or role questions such as who are you.\n",
    "Conversation management messages such as can you help me.\n",
    "\n",
    "For these inputs, respond briefly without using retrieval.\n",
    "\n",
    "Retrieval must ONLY be used for factual questions related to NELFUND, including questions about student loans, eligibility, application processes, repayment, disbursement, participating institutions, policies, timelines, or responsibilities of students, institutions, or government bodies.\n",
    "\n",
    "You must never answer a factual NELFUND question without retrieving documents.\n",
    "\n",
    "If retrieval is performed and no relevant information is found, you must respond with:\n",
    "\n",
    "Can't provide\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CONVERSATION MEMORY AND FOLLOW-UP HANDLING\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "Treat the conversation as continuous and stateful.\n",
    "\n",
    "Use previous user questions and your prior responses to understand context.\n",
    "\n",
    "When the user asks a follow-up question, assume it refers to the most recent NELFUND topic discussed unless clearly stated otherwise.\n",
    "\n",
    "Resolve vague references and pronouns such as it, they, this loan, or the fund using the immediate conversation context.\n",
    "\n",
    "Even for follow-up questions, you may only use information found in retrieved documents.\n",
    "\n",
    "If a follow-up question cannot be answered from retrieved documents, respond with:\n",
    "\n",
    "Can't provide any information on that.\n",
    "\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "RESPONSE RULES\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "All factual answers must be directly supported by retrieved documents.\n",
    "\n",
    "Every factual answer must include a citation to the retrieved source documents in the format required by the system.\n",
    "\n",
    "Do not cite sources when responding with Can't provide.\n",
    "\n",
    "Answers must be clear, concise, and factual.\n",
    "\n",
    "Use plain text only.\n",
    "\n",
    "Do not use asterisks, bullet points, markdown, symbols, decorative formatting, or emojis in responses.\n",
    "\n",
    "Do not repeat the user's question in your answer.\n",
    "\n",
    "Do not speculate, infer, or provide opinions.\n",
    "\n",
    "Do not answer hypothetical questions unless explicitly covered in the retrieved documents.\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ System prompt configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd713c00",
   "metadata": {},
   "source": [
    "**Define Agent Nodes and Build the Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bdef775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agentic RAG system compiled\n"
     ]
    }
   ],
   "source": [
    "tools = [retrieve_nelfund_docs]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to retrieve or answer directly.\n",
    "    \"\"\"\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: dict) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide whether to call tools or finish.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if getattr(last_message, \"tool_calls\", False):\n",
    "        if state.get(\"retrieval_done\", False):\n",
    "            return \"__end__\"\n",
    "        state[\"retrieval_done\"] = True  # <-- store flag in dict\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "builder = StateGraph(dict)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", should_continue, {\"tools\": \"tools\", \"__end__\": END})\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "agent = builder.compile()\n",
    "print(\"‚úÖ Agentic RAG system compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6b6f1",
   "metadata": {},
   "source": [
    "**MongoDB Thread Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7c67901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active thread: 3a464f7e-2d0d-4285-8396-523e5d689c01\n"
     ]
    }
   ],
   "source": [
    "def load_state(user_id, thread_id):\n",
    "    docs = messages_collection.find({\"user_id\": user_id, \"thread_id\": thread_id}).sort(\"timestamp\", 1)\n",
    "    return {\"messages\": [{\"role\": d[\"role\"], \"content\": d[\"message\"]} for d in docs]}\n",
    "\n",
    "user_id = \"user_001\"\n",
    "thread = threads_collection.find_one({\"user_id\": user_id})\n",
    "\n",
    "if not thread:\n",
    "    thread_id = str(uuid.uuid4())\n",
    "    threads_collection.insert_one({\n",
    "        \"user_id\": user_id,\n",
    "        \"thread_id\": thread_id,\n",
    "        \"created_at\": datetime.now(timezone.utc)\n",
    "    })\n",
    "else:\n",
    "    thread_id = thread[\"thread_id\"]\n",
    "\n",
    "print(\"Active thread:\", thread_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0a3c8",
   "metadata": {},
   "source": [
    "**Query Agent & Intent Gate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a85523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting_intent(query: str) -> bool:\n",
    "    greetings = {\n",
    "        \"hi\", \"hello\", \"hey\", \"good morning\", \"good afternoon\", \"good evening\",\n",
    "        \"thanks\", \"thank you\", \"who are you\", \"can you help me\"\n",
    "    }\n",
    "    return query.lower().strip() in greetings\n",
    "\n",
    "def query_agent(user_input: str, thread_id: str = user_id):\n",
    "    \"\"\"\n",
    "    Improved query function with clearer output.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\\nüë§ User: {user_input}\\n{'='*70}\\n\")\n",
    "\n",
    "    if greeting_intent(user_input):\n",
    "        print(\"ü§ñ Agent: Hello. How can I help you with NELFUND?\")\n",
    "        print(f\"\\nüìä Decision: DID NOT USE RETRIEVAL\\n{'='*70}\\n\")\n",
    "        return\n",
    "\n",
    "    state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=user_input),\n",
    "        AIMessage(content=\"Hi, How can I help you today?\")  \n",
    "    ]\n",
    "    }\n",
    "    result = agent.invoke(state, config={\"configurable\": {\"thread_id\": thread_id}})\n",
    "\n",
    "    used_retrieval = False\n",
    "    final_answer = None\n",
    "\n",
    "    for message in result[\"messages\"]:\n",
    "        if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "            used_retrieval = True\n",
    "            print(\"üîç Agent: [Calling retrieval tool...]\")\n",
    "        if getattr(message, \"content\", None):\n",
    "            final_answer = message.content\n",
    "\n",
    "    if final_answer:\n",
    "        print(f\"ü§ñ Agent: {final_answer}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No response generated after retrieval!\")\n",
    "\n",
    "    print(f\"\\nüìä Decision: {'USED RETRIEVAL' if used_retrieval else 'ANSWERED DIRECTLY'}\\n{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9a7649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Hi, My name is Olajcodes\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: Hi, How can I help you today?\n",
      "\n",
      "üìä Decision: ANSWERED DIRECTLY\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_agent(\"Hi, My name is Olajcodes\", thread_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdf828",
   "metadata": {},
   "source": [
    "**Trying to test Chat History API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'message': 'Message saved'}\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# # Send a new message\n",
    "# res = requests.post(\n",
    "#     \"http://127.0.0.1:8000/messages\",\n",
    "#     json={\"user_id\": \"user123\", \"role\": \"user\", \"message\": \"Hello from notebook!\"}\n",
    "# )\n",
    "# print(res.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41250f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# # Send a new message\n",
    "# res = requests.post(\n",
    "#     \"http://127.0.0.1:8000/messages\",\n",
    "#     # json={\"user_id\": thread_id, \"role\": \"user\", \"message\": \"Still figuring it out!\"}\n",
    "# )\n",
    "# print(res.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa43a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch conversation\n",
    "# res = requests.get(\"http://127.0.0.1:8000/messages/user123\")\n",
    "# print(res.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
